{% set name = "abess" %}
{% set version = "0.4.6" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 9830fb70a2854faf233876eb81b27a3e7265533af682f9f8fe0d4e1de0293cb6

build:
  number: 1
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  build:
    - {{ compiler('cxx') }}
    - python
    - make
    - cmake
    - llvm-openmp   # [osx]
    - libgomp       # [linux]
    - intel-openmp  # [win]
  host:
    - pip
    - python
    - numpy
    - "pybind11 >=2.6.0"
  run:
    - {{ pin_compatible('numpy') }}
    - "scipy"
    - "pandas"
    - "scikit-learn >=0.24"
    - _openmp_mutex   # [linux]
    - libstdcxx-ng    # [linux]
    - libgcc-ng       # [linux]
    - libcxx          # [osx]
    - vs2015_runtime  # [win]
    - python

test:
  imports:
    - abess
  requires:
    - pip
  commands:
    - pip check

about:
  home: https://abess.readthedocs.io
  license: GPL-2.0-or-later
  license_family: GPL
  license_file: LICENSE
  summary: Fast Best-Subset Selection
  description: |
    abess (Adaptive BEst-Subset Selection) library aims to solve general best subset selection, i.e., 
    find a small subset of predictors such that the resulting model is expected to have the highest accuracy. 
    This library implements a generic algorithm framework to find the optimal solution in an extremely fast way. 
    This framework now supports the detection of best subset under: 
    linear regression, (multi-class) classification, censored-response modeling, 
    multi-response modeling (a.k.a. multi-tasks learning), etc. 
    It also supports the variants of best subset selection like group best subset selection. 
    Especially, the time complexity of (group) best subset selection for linear regression is certifiably polynomial.
  doc_url: https://abess.readthedocs.io
  dev_url: https://github.com/abess-team/abess

extra:
  recipe-maintainers:
    - oooo26
    - Mamba413
